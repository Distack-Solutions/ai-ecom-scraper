================================================
File: /software/urls.py
================================================
"""
URL configuration for software project.

The `urlpatterns` list routes URLs to views. For more information please see:
    https://docs.djangoproject.com/en/4.2/topics/http/urls/
Examples:
Function views
    1. Add an import:  from my_app import views
    2. Add a URL to urlpatterns:  path('', views.home, name='home')
Class-based views
    1. Add an import:  from other_app.views import Home
    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
Including another URLconf
    1. Import the include() function: from django.urls import include, path
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
"""
from django.contrib import admin
from django.urls import path, include
from django.conf.urls.static import static
from django.conf import settings

urlpatterns = [
    path('i18n/', include('django.conf.urls.i18n')),
    path('admin/', admin.site.urls),
    path('scraper/', include('apps.scraper.urls')),
    path('ai/', include('apps.ai.urls')),
    path('', include('apps.accounts.urls')),
    path('', include('apps.job_management.urls')),
    path('', include('apps.work_tracker.urls')),
    path('api-auth/', include('rest_framework.urls'))
]

if settings.DEBUG:
    urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)

================================================
File: /apps/ai/models.py
================================================
from django.db import models
from apps.scraper.models import Product
from django.db import models

# python manage.py makemigrations
# python manage.py migrate

# Create your models here.
class ProductAIVersion(models.Model):
    title = models.CharField(max_length=255, verbose_name="AI Generated Title")
    expanded_description = models.TextField(verbose_name="Expanded Description")
    short_description = models.TextField(verbose_name="Short Description")
    meta_description = models.CharField(max_length=255, verbose_name="Meta Description")
    focus_keyphrase = models.CharField(max_length=255, verbose_name="Focus Keyphrase")
    product = models.OneToOneField(Product, on_delete=models.CASCADE, related_name="ai_version", verbose_name="Product")

    def get_images(self):
        images = self.product.images.all()
        wc_images = []
        i = 1

        if self.product.thumbnail:
            thumbnail_url = None
            if self.product.thumbnail.url:
                thumbnail_url = self.product.thumbnail.url

            if self.product.thumbnail.image.url:
                thumbnail_url = self.product.thumbnail.image.url

            if thumbnail_url:
                wc_images.append({
                    'name': f"{self.product.title} - Thumbnail",
                    'src': thumbnail_url
                })

        for image in images:
            image_url = None
            image_name = f'{self.product.title} - Gallery image {i}'
            if image.image_file:
                image_url = image.image_file.url
            else:
                image_url = image.image_url

            wc_images.append(
                {
                    'name': image_name,
                    'src': image_url
                })
            i+=1

        return wc_images

    def __str__(self):
        return f"AI Version of {self.product.title}"

    class Meta:
        verbose_name = "Product AI Version"
        verbose_name_plural = "Product AI Versions"





class OpenAIAPIUsage(models.Model):
    endpoint = models.CharField(max_length=255, help_text="The OpenAI endpoint used, e.g., 'text-davinci-003'.")
    total_tokens = models.IntegerField(help_text="Total tokens used for the API request.")
    prompt_tokens = models.IntegerField(help_text="Prompt token used for the API request.")
    completion_tokens = models.IntegerField(help_text="Completion tokens generated for the API request.")
    request_timestamp = models.DateTimeField(auto_now_add=True, help_text="The timestamp when the API request was made.")
    response_time = models.FloatField(null=True, blank=True, help_text="Response time in seconds, if tracked.")
    
    class Meta:
        ordering = ['-request_timestamp']
        verbose_name = "OpenAI API Usage"
        verbose_name_plural = "OpenAI API Usages"

    def __str__(self):
        return f"{self.endpoint} - {self.total_tokens} tokens on {self.request_timestamp}"


================================================
File: /apps/ai/urls.py
================================================
from django.urls import path
from . import views

app_name = 'ai'

urlpatterns = [
    # Other URLs here...
    path('update-product-ai-details/<int:product_id>/', views.update_ai_details, name='update_ai_details'),
    path('rengenerate-product-details/<int:product_id>/', views.regenerate_ai, name='regenerate_ai'),

]


================================================
File: /apps/ai/views.py
================================================
from django.shortcuts import render, get_object_or_404, redirect
from django.contrib import messages
from django.urls import reverse
from .models import Product, ProductAIVersion
from django.contrib.auth.decorators import login_required
from django.http import JsonResponse

@login_required
def update_ai_details(request, product_id):
    product = get_object_or_404(Product, id=product_id)
    
    if not hasattr(product, 'ai_version'):
        # If there is no AI version associated with the product, return a 404 or handle appropriately
        messages.error(request, "AI details not found for this product.")
        return redirect(reverse('scraper:product_detail', kwargs={'product_id': product_id}))

    ai_version = product.ai_version

    if request.method == 'POST':
        # Get form data from POST request
        ai_title = request.POST.get('ai_title')
        ai_expanded_description = request.POST.get('ai_expanded_description')
        ai_short_description = request.POST.get('ai_short_description')
        ai_meta_description = request.POST.get('ai_meta_description')
        ai_focus_keyphrase = request.POST.get('ai_focus_keyphrase')

        # Update AI Version fields
        ai_version.title = ai_title
        ai_version.expanded_description = ai_expanded_description
        ai_version.short_description = ai_short_description
        ai_version.meta_description = ai_meta_description
        ai_version.focus_keyphrase = ai_focus_keyphrase
        
        # Save the updated AI version
        ai_version.save()

        # Add success message
        messages.success(request, "AI details updated successfully.")

        # Redirect to product detail view with query parameter to scroll to AI details
        return redirect(f"{reverse('scraper:product_detail', kwargs={'product_id': product.id})}?scroll_to_ai=true")

    return redirect('scraper:product_detail', product_id=product.id)


@login_required
def regenerate_ai(request, product_id):
    if request.method == 'POST':
        # Get the product by ID or return a 404 if not found
        product = get_object_or_404(Product, id=product_id)
        ai_details = product.generate_ai_details()
        product.create_or_update(ai_details=ai_details)
        # Return JSON response for successful approval
        return JsonResponse({
            'ai_details': ai_details,
            'success': True, 
            'message': f'Details has been updated.'
        })
    
    # If not a POST request, return a 405 Method Not Allowed
    return JsonResponse({'success': False, 'message': 'Invalid request method.'}, status=405)


================================================
File: /apps/job_management/models.py
================================================
from django.db import models
from apps.accounts.models import Customer, Address
from django.contrib.auth.models import User
from datetime import datetime, timedelta
from django.db.models import Q
from django.db.models import Value, CharField
# Create your models here.

# python manage.py makemigrations
# python manage.py migrate
# python manage.py runserver


class Check(models.Model):
    title = models.CharField(max_length=50)
    description = models.TextField(
        help_text="Enter the check description here.", blank=True, null=True
    )


class CheckList(models.Model):
    checks = models.ManyToManyField(Check)
    name = models.CharField(max_length=255)

    def __str__(self):
        """Return the name of the checklist."""
        return self.name



class Job(models.Model):
    class Status(models.TextChoices):
        NOT_INITIATED = "Not Initiated", "Not Initiated"
        PENDING = "Pending", "Pending"
        COMPLETE = "Complete", "Complete"
        IMMEDIATE_ACTION = "Immediate Action", "Immediate Action"

    display_id = models.CharField(max_length=255, null=True, blank=True)
    myob_uid = models.CharField(unique=True, max_length=50, null=True, blank=True)
    myob_row_version = models.BigIntegerField(null=True, blank=True)
    
    name = models.CharField(max_length=50)
    number = models.CharField(max_length=30)
    description = models.TextField(null=True, blank=True, default="No description is provided.")
    parent_job = models.ForeignKey("self", on_delete=models.CASCADE, null=True, blank=True)
    status = models.CharField(max_length=20, choices=Status.choices, default=Status.NOT_INITIATED, blank=True)
    is_active = models.BooleanField(default=False)
    start_date = models.DateField(null=True, blank=True)
    finish_date = models.DateTimeField(null=True, blank=True)
    last_modified_date = models.DateTimeField(null=True, blank=True)
    checklist = models.ForeignKey(CheckList, on_delete=models.SET_NULL, null=True, blank=True)

    address = models.ForeignKey(Address, on_delete=models.CASCADE, null=True, blank=True)
    customer = models.ForeignKey(Customer, on_delete=models.CASCADE, null=True, blank=True)
    created_at = models.DateField(auto_now_add=True, blank=True, null=True)
    uri = models.URLField(null=True, blank=True)

    @property
    def get_status(self):
        status_dictionary = {
            "NI": ("Not Initiated", "secondary"),
            "PN": ("Pending", "warning"),
            "CP": ("Complete", "success"),
            "IA": ("Immediate Action", "danger"),
            "Not Initiated": ("Not Initiated", "secondary"),
            "Pending": ("Pending", "warning"),
            "Complete": ("Complete", "success"),
            "Immediate Action": ("Immediate Action", "danger")
        }
        return status_dictionary[self.status]

    @property
    def complete_name(self):
        return f"{self.name} - {self.number}"

    def get_assignments(self):
        return Assignment.objects.filter(job = self)

    def __str__(self):
        return self.complete_name




class Roster(models.Model):
    name = models.CharField(max_length = 255, null=True, blank=True)
    start_date = models.DateField(null=True)
    finish_date = models.DateField(null=True)
    created = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        unique_together = ("start_date", "finish_date")

    def __str__(self):
        return f'{self.start_date}  to  {self.finish_date}'


class Plant(models.Model):
    number = models.CharField(max_length=10)
    description = models.CharField(max_length=100)

    def __str__(self):
        return f"{self.number} - {self.description}"


class Assignment(models.Model):
    roster = models.ForeignKey(Roster, on_delete=models.SET_NULL, null=True, blank=True)
    job = models.ForeignKey(Job, on_delete=models.CASCADE)
    employee = models.ForeignKey('accounts.Employee', on_delete=models.CASCADE)
    date = models.DateField()
    start_time = models.TimeField()
    finish_time = models.TimeField(blank=True, null=True)
    plant = models.ForeignKey(
        Plant, on_delete=models.SET_NULL, null=True, blank=True
    )
    assigned_by = models.ForeignKey(User, on_delete=models.SET_NULL, null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)

    def __str__(self):
        return f'{self.job} -> {self.employee}'


    def get_timesheet(self):
        if hasattr(self, 'timesheet'):
            return self.timesheet
        return None

    class Meta:
        ordering = ('-created_at',)

================================================
File: /apps/job_management/urls.py
================================================
from django.urls import path
from . import views
from django.views.i18n import set_language

app_name = "job_management"

urlpatterns = [
    # path('jobs', views.all_jobs, name='job_home'),
    path('jobs/', views.all_jobs, name='job-home'),
    path('jobs/<job_id>/view', views.single_job_view, name='single-job'),
    

    path('jobs/assignments', views.job_assignments, name='job-assignments'),
    path('jobs/assignments/<assignment_id>/view', views.single_job_assignment, name='single-job-assignment'),
    path('jobs/assignments/<assignment_id>/approve', views.approve_single_job_assignment, name='approve-job-assignment'),



    path('jobs/assignments/create', views.create_job_assignments, name='create-job-assignments'),
    path('jobs/assignments/fetch', views.fetch_job_assignments, name='fetch-job-assignments'),

    path('jobs/search_job', views.search_job, name='search_job'),

]


================================================
File: /apps/job_management/views.py
================================================
from django.shortcuts import render, redirect
from django.http import HttpResponse
from .data_handler import MyOBToDjangoSync
from .models import Job
from django.core.paginator import Paginator
from django.db.models import Q, Value, CharField, F
import random
from faker import Faker
from django.utils import timezone
from .models import Assignment, Job
from apps.accounts.models import Employee
from datetime import datetime
from django.http import JsonResponse
from django.db.models.functions import Concat   
from django.conf import settings
from .forms import *
from django.contrib import messages
from django.contrib.auth.decorators import login_required
TOTAL_RECORDS_LIMIT = settings.TOTAL_RECORDS_LIMIT

@login_required
def all_jobs(request):
    query = request.GET.get('q')
    all_jobs_list = Job.objects.all()

    if query:
        # Apply search filter here
        all_jobs_list = all_jobs_list.annotate(
            complete_name1=Concat('name', Value(' - '), 'number')
        )

        all_jobs_list = all_jobs_list.filter(
            Q(complete_name1__icontains=query) | 
            Q(customer__name__icontains=query)
        )


    paginator = Paginator(all_jobs_list, TOTAL_RECORDS_LIMIT)  # Change 10 to the number of items per page you desire
    page_number = request.GET.get('page')
    page_obj = paginator.get_page(page_number)
    context = {
        'jobs': page_obj,
        'page': 'job'
    }
    return render(request, "all_jobs.html", context)

@login_required
def single_job_view(request, job_id):
    from apps.work_tracker.models import Session, Timesheet
    try:
        job = Job.objects.get(id = job_id)
    except Exception as e:
        messages.error(request, f"Job with id {job_id} does not exist.")
        return redirect("job_management:job-home")

    fields_data = {}
    exclude = ['myob_row_version', 'uri', 'myob_uid', 'is_active']
    for field in job._meta.fields:
        if field.name not in exclude:
            key = field.verbose_name
            value = getattr(job, field.name)
            fields_data[key] = value
    fields_data['status'] = job.get_status[0]


    sessions = Session.objects.filter(timesheet__assignment__job=job)
    groupview = request.GET.get('groupview')
    group_assignments = []
    if groupview == 'true':
        group_assignments = Assignment.objects.filter(job=job)

    context = {
        'group_assignments': group_assignments,
        'sessions': sessions,
        'job': job,
        'fields_data': fields_data,
        'page': 'job'

    }
    return render(request, "single-job.html", context)

def fetch_job_assignments(request):
    if not request.user.is_authenticated:
        return JsonResponse([], safe=False)
    
    start_date_str = request.GET.get('start')
    end_date_str = request.GET.get('end')
    
    # Convert start and end date strings to datetime objects
    start_date = datetime.strptime(start_date_str, "%Y-%m-%dT%H:%M:%S%z") if start_date_str else None
    end_date = datetime.strptime(end_date_str, "%Y-%m-%dT%H:%M:%S%z") if end_date_str else None

    assignments_queryset = Assignment.objects.all()
    if start_date and end_date:
        assignments_queryset = assignments_queryset.filter(date__range=[start_date, end_date])

    assignment_list = []
    for assignment in assignments_queryset:
        title = f'<div class="p-2"><div class="mb-2">{assignment.job.number}</div><div class="d-flex align-items-center"><i class="material-icons fs-6">person</i><span class="mx-2">{assignment.employee}</span><div></<div>'
        date = assignment.date.strftime("%Y-%m-%d")
        assignment_list.append({
            'id': assignment.id,
            'title': title,
            'date': date
        })

    return JsonResponse(assignment_list, safe=False)



def populate_assignment_model(current_user):
    fake = Faker()
    jobs = Job.objects.all()
    employees = Employee.objects.all()
    
    for _ in range(100):
        job = random.choice(jobs)
        employee = random.choice(employees)
        date = fake.date_time_this_month(before_now=True, after_now=False, tzinfo=None)
        start_time = fake.time(pattern="%H:%M:%S", end_datetime=None)
        finish_time = fake.time(pattern="%H:%M:%S", end_datetime=None)
        while finish_time <= start_time:
            finish_time = fake.time(pattern="%H:%M:%S", end_datetime=None)
        assigned_by = current_user  # You might want to set this to a specific user if needed
        created_at = fake.date_time_this_month(before_now=True, after_now=False, tzinfo=None)

        assignment = Assignment.objects.create(
            job=job,
            employee=employee,
            date=date,
            start_time=start_time,
            finish_time=finish_time,
            assigned_by=assigned_by,
            created_at=created_at
        )
        print(assignment)

    return 'Successfully populated Assignment model with fake data'


@login_required
def job_assignments(request):
    query = request.GET.get('q')
    all_jobs_assignment_list = Assignment.objects.all()


    if query:
        # Apply search filter here
        all_jobs_assignment_list = all_jobs_assignment_list.annotate(
            complete_job_name=Concat('job__name', Value(' - '), 'job__number'),
            full_employee_name=Concat('employee__user__first_name', Value(' '), 'employee__user__last_name'),
        )

        all_jobs_assignment_list = all_jobs_assignment_list.filter(
            Q(complete_job_name__icontains=query) | 
            Q(full_employee_name__icontains=query)
        )  

    paginator = Paginator(all_jobs_assignment_list, TOTAL_RECORDS_LIMIT)  # Change 10 to the number of items per page you desire
    page_number = request.GET.get('page')
    page_obj = paginator.get_page(page_number)
    context = {
        'assignments': page_obj,
        'page': 'assignment'
    }


    return render(request, "job-assignments.html", context)


@login_required
def single_job_assignment(request, assignment_id):
    try:
        assignment = Assignment.objects.get(id = assignment_id)
    except Exception as e:
        messages.error(request, f"Job Assignment with id {assignment_id} does not exist.")
        return redirect("job_management:job-assignments")

    context = {
        'assignment': assignment,
        'page': 'assignment',
        'timesheet': assignment.get_timesheet(),
    }
    return render(request, "single-assignment.html", context)

@login_required
def approve_single_job_assignment(request, assignment_id):
    try:
        assignment = Assignment.objects.get(id = assignment_id)
    except Exception as e:
        messages.error(request, f"Job Assignment with id {assignment_id} does not exist.")
        return redirect("job_management:job-assignments")

    timesheet = assignment.get_timesheet()
    if timesheet:
        timesheet.status = "Approved"
        timesheet.save()
    messages.success(request, "Timesheet of this job assignment has been approved")
    return redirect("job_management:single-job-assignment", assignment_id=assignment_id)

@login_required
def create_job_assignments(request):
    if request.method == 'POST':
        form = AssignmentForm(request.POST)
        if form.is_valid():
            new_assignment = Assignment(**form.cleaned_data, assigned_by=request.user)
            new_assignment.save()
            messages.success(request, "Job has been assigned successfully")
            
            if request.POST.get('action') == 'save':
                return redirect('job_management:job-assignments')
            elif request.POST.get('action') == 'save_and_add_another':
                return redirect('job_management:create-job-assignments')
                # Optionally, you can add a success message here
    else:
        form = AssignmentForm(initial={
            'job':request.GET.get('job'),
            'employee':request.GET.get('employee'),
            'date': request.GET.get('date')
        })
    
    context = {
        'page': 'assignment',
        'form': form
    }
    return render(request, "create-job-assignment.html", context)



def search_job(request):
    if not request.user.is_authenticated:
        return JsonResponse([], safe=False)
    
    if 'term' in request.GET:
        term = request.GET.get('term')
        print(term, 'wow')
        if term and len(term) < 2:
            return JsonResponse([], safe=False)

        # Apply search filter here
        all_jobs_list = Job.objects.annotate(
            complete_name1=Concat('name', Value(' - '), 'number')
        ).filter(complete_name1__icontains=term)
        results = [{'id': job.id, 'text': str(job)} for job in all_jobs_list]
        return JsonResponse(results, safe=False)
    else:
        return JsonResponse({'error': 'Invalid request'}, status=400)

================================================
File: /apps/scraper/models.py
================================================
from django.db import models
from django.contrib.auth.models import User
from django.utils import timezone


# python manage.py makemigrations
# python manage.py migrate


class SourceWebsite(models.Model):
    name = models.CharField(max_length=255, verbose_name="Website Name")
    logo = models.ImageField(upload_to='website_logos/', verbose_name="Website Logo")
    script_name = models.CharField(max_length=255, verbose_name="Scraper Script Name")
    url = models.URLField(max_length=255, verbose_name="Website URL")

    def __str__(self):
        return self.name

    class Meta:
        verbose_name = "Source Website"
        verbose_name_plural = "Source Websites"


class Criteria(models.Model):
    TYPE_CHOICES = [
        ('equals', 'Equals'),
        ('less_than', 'Less Than'),
        ('greater_than', 'Greater Than'),
        ('not', 'Not'),
    ]

    name = models.CharField(max_length=255, verbose_name="Criteria Name")
    key = models.CharField(max_length=255, verbose_name="Criteria Key")
    type = models.CharField(max_length=20, choices=TYPE_CHOICES, verbose_name="Type")
    value = models.CharField(max_length=255, verbose_name="Value")
    is_required = models.BooleanField(default=False, verbose_name="Is Required")

    def __str__(self):
        return f"{self.name} ({self.type})"

    class Meta:
        verbose_name = "Criteria"
        verbose_name_plural = "Criterias"



class ScrapingProcess(models.Model):
    STATUS_CHOICES = [
        ('pending', 'Pending'),
        ('running', 'Running'),
        ('completed', 'Completed'),
        ('failed', 'Failed'),
    ]

    search_query = models.CharField(max_length=255, verbose_name="Search Query")
    source_websites = models.ManyToManyField(SourceWebsite, verbose_name="Source Websites")
    criterias = models.ManyToManyField(Criteria, null=True, blank=True, verbose_name="Criterias")
    max_records = models.PositiveIntegerField(default=0, verbose_name="Max Records")
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='pending', verbose_name="Status")
    started_by = models.ForeignKey(User, on_delete=models.CASCADE, verbose_name="Started By")
    started_at = models.DateTimeField(auto_now_add=True, verbose_name="Started At")
    completed_at = models.DateTimeField(null=True, blank=True, verbose_name="Completed At")

    def get_duration(self):
        """Returns the duration of the scraping process in a human-readable format."""
        if self.completed_at:
            # If completed_at is set, return the duration
            duration = self.completed_at - self.started_at
        else:
            # If not completed, return the duration from started_at to the current time
            duration = timezone.now() - self.started_at
        
        # Calculate hours, minutes, and seconds
        seconds = duration.total_seconds()
        hours = seconds // 3600
        minutes = (seconds % 3600) // 60
        seconds = seconds % 60

        # Format the duration in a human-readable string
        duration_str = f"{int(hours)}h {int(minutes)}m {int(seconds)}s"
        
        return duration_str


    def __str__(self):
        return f"Scraping {self.search_query} by {self.started_by}"

    class Meta:
        verbose_name = "Scraping Process"
        verbose_name_plural = "Scraping Processes"


class PageScreenshot(models.Model):
    image = models.ImageField(upload_to="page-screenshot", null=True, blank=True)
    url = models.URLField(null=True, blank=True)

class License(models.Model):
    json = models.JSONField(null=True, blank=True)


class ThumbnailImage(models.Model):
    image = models.ImageField(upload_to='thumbnail_images/', null=True, blank=True, verbose_name="Thumbnail Image")
    url = models.URLField(null=True, blank=True, verbose_name="Thumbnail URL")
    
    def __str__(self):
        return self.url if self.url else f"Image: {self.image.name}" if self.image else "No Thumbnail"

    class Meta:
        verbose_name = "Thumbnail Image"
        verbose_name_plural = "Thumbnail Images"


class Product(models.Model):
    STATUS_CHOICES = [
        ('draft', 'Draft'),
        ('under_review', 'Under Review'),
        ('declined', 'Declined'),
        ('approved', 'Approved'),
        ('published', 'Published'),
        ('archived', 'Archived'),
    ]
    sku = models.CharField(max_length=50, unique=True, null=True, blank=True)
    scraped_by = models.ForeignKey(ScrapingProcess, on_delete=models.CASCADE, verbose_name="Scraped By")
    title = models.CharField(max_length=255, verbose_name="Product Title")
    category = models.CharField(max_length=255, null=True, blank=True, verbose_name="Category")
    description = models.TextField(verbose_name="Description")
    thumbnail = models.OneToOneField(ThumbnailImage, on_delete=models.SET_NULL, null=True, blank=True, verbose_name="Thumbnail")
    source_website = models.ForeignKey(SourceWebsite, on_delete=models.CASCADE, verbose_name="Source Website")
    is_published = models.BooleanField(default=False, verbose_name="Is Published")
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='under_review', verbose_name="Status")
    license = models.OneToOneField(License, on_delete=models.SET_NULL, blank=True, null=True, verbose_name="Product License")
    page_screenshot = models.OneToOneField(PageScreenshot, on_delete=models.SET_NULL, verbose_name="Page Screenshot", null=True, blank=True)
    is_commercial_allowed = models.BooleanField(default=False, verbose_name="Is Commercial Allowed")
    created_at = models.DateTimeField(auto_now_add=True, verbose_name="Created At")
    updated_at = models.DateTimeField(auto_now=True, verbose_name="Updated At")
    publishing_message = models.CharField(max_length=255, null=True, blank=True)

    def get_website_url(self):
        url = "#"
        if self.source_website.name == "Printables":
            original_sku = self.sku.split("-")[1:]
            original_sku = "-".join(original_sku)
            url = f"https://www.printables.com/model/{original_sku}"

        if self.source_website.name == "STLFLIX":
            original_sku = self.sku.split("-")[1:]
            original_sku = "-".join(original_sku)
            url = f"https://platform.stlflix.com/product/{original_sku}"
            
        if self.source_website.name == "Makerworld":
            original_sku = self.sku.split("-")[1:]
            original_sku = "-".join(original_sku)
            url = f"https://makerworld.com/en/models/{original_sku}"

        return url

    def get_categories(self):
        category_list = []
        if self.category:
            category_list = self.category.split(",")
        
        return category_list

    def generate_ai_details(self):
        from apps.ai.libs.openai_generator import AIGenerator
        ai_generator = AIGenerator(product=self)
        ai_generator.generate_ai_response()
        ai_response = ai_generator.get_response_content()
        return ai_response

    def create_or_update(self, ai_details):
        from apps.ai.models import ProductAIVersion
        ai_version, created = ProductAIVersion.objects.get_or_create(
            product=self,
            defaults=ai_details
        )

        if not created:
            ai_version.title = ai_details.get('title', 'title')
            ai_version.expanded_description = ai_details.get('expanded_description', 'expanded_description')
            ai_version.short_description = ai_details.get('short_description', 'short_description')
            ai_version.meta_description = ai_details.get('meta_description', 'meta_description')
            ai_version.focus_keyphrase = ai_details.get('focus_keyphrase', 'focus_keyphrase')
            ai_version.save()
        return ai_version

    def get_serialized_ai_version(self):
        if hasattr(self, 'ai_version'):
            ai_version = getattr(self, 'ai_version')
            return {
                'title': ai_version.title, 
                'expanded_description': ai_version.expanded_description,
                'short_description':ai_version.short_description,
                'meta_description':ai_version.meta_description,
                'focus_keyphrase':ai_version.focus_keyphrase
            }
        return None

    def populate_printables_data(self, products):
        for product in products:
            print(product)

    def __str__(self):
        return self.title


    class Meta:
        ordering = ('-created_at', '-updated_at')
        verbose_name = "Product"
        verbose_name_plural = "Products"



class Image(models.Model):
    image_url = models.URLField(null=True, blank=True)
    image_file = models.ImageField(null=True, blank=True, upload_to='product_images/', verbose_name="Image File")
    product = models.ForeignKey(Product, on_delete=models.CASCADE, related_name="images", verbose_name="Product")

    def __str__(self):
        return str(self.product)

    class Meta:
        verbose_name = "Image"
        verbose_name_plural = "Images"





================================================
File: /apps/scraper/urls.py
================================================
from django.urls import path
from . import views
from django.views.i18n import set_language

app_name = "scraper"

urlpatterns = [
    # path('jobs', views.all_jobs, name='job_home'),
    path('products/', views.all_products, name='products'),
    path('products/<int:product_id>/', views.product_detail, name='product_detail'),  # Add this line    
    path('products/<int:product_id>/approve', views.approve_product, name='approve-product'),    
    path('products/<int:product_id>/approve-ajax', views.approve_product_via_ajax, name='approve-product-ajax'),
    path('products/<int:product_id>/decline', views.decline_product, name='decline-product'),
    path('products/<int:product_id>/delete', views.delete_product, name='delete-product'),
    
    path('products/<int:product_id>/screenshot/', views.view_screenshot, name='view_screenshot'),

    path('processes/initiate/', views.initiate_process, name='initiate-process'),
    path('processes/', views.processes_list, name='processes'),

    path('ajax/wc/publish-products', views.ajax_upload_product_to_wc, name='upload-wc-product'),

    path('ajax/products/operation', views.process_products_operation, name='process-products-operation'),

    path('ajax/products/operation/sse', views.process_products_sse, name='process-products-sse'),

    path('ajax/products/scraping/sse', views.initiate_scraping_process, name='scrape-products-sse')

]


================================================
File: /apps/scraper/views.py
================================================
from django.contrib.auth.decorators import login_required
from .models import *
from django.shortcuts import render, redirect
from .forms import ScrapingProcessForm
from apps.scraper.libs.printables import PrintablesProductScrap
from apps.scraper.libs.stlflix import StlflixProductScrap
from apps.scraper.libs.makerworld import MakerWorldProductScrap
from apps.scraper.libs.scraping_processor import ProductScraperProcessor
from django.shortcuts import render, get_object_or_404
from django.contrib import messages
from django.shortcuts import get_object_or_404, render
from django.contrib.auth.decorators import login_required
import os, time
from django.http import JsonResponse

from django.views.decorators.csrf import csrf_exempt
from apps.scraper.libs.wc import WooCommerceManager

from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from .models import Product
from django.http import StreamingHttpResponse
from time import sleep
import json
# Create your views here.
from django.core.paginator import Paginator
from django.shortcuts import render
from django.http import StreamingHttpResponse
from django.contrib import messages
from django.db.models import Q


def makerworld(request):
    scraper = MakerWorldProductScrap(query="apple", limit=10)
    scraper.get_products()
    structured_data = scraper.to_model_data()
    return JsonResponse(structured_data, safe=False)


@login_required
def all_products(request):
    # Retrieve query parameters
    search_query = request.GET.get('search', '')
    status_filter = request.GET.get('status', '')
    per_page = int(request.GET.get('per_page', 10))  # Default to 10 products per page

    # Start with all products
    products = Product.objects.all().order_by('-created_at')

    # Apply search filter
    if search_query:
        products = products.filter(title__icontains=search_query)

    # Apply status filter
    if status_filter and status_filter != 'all':
        products = products.filter(status=status_filter)

    # Implement pagination
    paginator = Paginator(products, per_page)  # Show per_page products per page
    page_number = request.GET.get('page')  # Get the page number from the request
    page_obj = paginator.get_page(page_number)  # Get the relevant page

    context = {
        'products': page_obj,  # Pass the paginated products
        'search_query': search_query,
        'status_filter': status_filter,
        'per_page': per_page,  # Pass per_page for UI controls
        'page': 'products',
    }
    return render(request, "volt/product.html", context)


@login_required
def delete_product(request, product_id):
    product = get_object_or_404(Product, id=product_id)
    product.delete()
    messages.success(request, "Product has been deleted successfully.")
    return redirect('scraper:products')

@login_required
def approve_product(request, product_id):
    # Get the product by ID or return a 404 if not found
    product = get_object_or_404(Product, id=product_id)
    
    # Change the product status to approved
    product.status = 'approved'
    product.save()

    # Display a success message
    messages.success(request, f'Product "{product.title}" has been approved.')
    
    return redirect('scraper:product_detail', product_id=product.id)
    # Redirect to the product list or some other page
    return redirect('scraper:products')  # Adjust URL name accordingly


@login_required
def approve_product_via_ajax(request, product_id):
    if request.method == 'POST':
        # Get the product by ID or return a 404 if not found
        product = get_object_or_404(Product, id=product_id)
        
        # Change the product status to approved
        product.status = 'approved'
        product.save()
        # Return JSON response for successful approval
        return JsonResponse({'success': True, 'message': f'Product "{product.title}" has been approved.'})
    
    # If not a POST request, return a 405 Method Not Allowed
    return JsonResponse({'success': False, 'message': 'Invalid request method.'}, status=405)


@login_required
def decline_product(request, product_id):
    # Get the product by ID or return a 404 if not found
    product = get_object_or_404(Product, id=product_id)
    
    # Change the product status to declined
    product.status = 'declined'
    product.save()

    # Display a success message
    messages.success(request, f'Product "{product.title}" has been declined.')
    return redirect('scraper:product_detail', product_id=product.id)
    
    # Redirect to the product list or some other page
    return redirect('scraper:products')  # Adjust URL name accordingly




@login_required
def view_screenshot(request, product_id):
    # Retrieve the product by its ID, or return 404 if not found
    product = get_object_or_404(Product, id=product_id)
    
    # Initialize variables
    screenshot_url = None
    is_pdf = False
    is_image = False
    
    # Check if the product has a screenshot, and determine the type (image or PDF)
    if product.page_screenshot:
        if product.page_screenshot.image:
            screenshot_url = product.page_screenshot.image.url
        elif product.page_screenshot.url:
            screenshot_url = product.page_screenshot.url
        
        # Determine the file type based on the extension
        if screenshot_url:
            file_extension = os.path.splitext(screenshot_url)[1].lower()
            if file_extension == '.pdf':
                is_pdf = True
            elif file_extension in ['.jpg', '.jpeg', '.png']:
                is_image = True
    
    # Pass the product, screenshot URL, and file type to the template
    context = {
        'product': product,
        'screenshot_url': screenshot_url,
        'is_pdf': is_pdf,
        'is_image': is_image,
        'page': 'products'

    }
    
    return render(request, 'volt/view_screenshot.html', context)


def fetch_products(scraping_process):
    """
    Fetch products based on the scraping process.
    This is just an example function, replace it with actual scraping logic.
    """
    for website in scraping_process.source_websites.all():
        print(f"Fetching products from {website.name} for ScrapingProcess {scraping_process.id}")
        
        if website.script_name == "printables.py":
            printables_scraper = PrintablesProductScrap(
                scraping_process.search_query,
                scraping_process.max_records
            )
            printables_scraper.get_products()
            structured_products = printables_scraper.to_model_data()

            for product in structured_products:
                try:
                    # Check if the product already exists
                    existing_product = Product.objects.filter(sku=product['sku']).first()
                    if existing_product:
                        print(f"Product with SKU {product['sku']} already exists. Skipping.")
                        continue

                    # Create License object if license data is present
                    internal_license = None
                    if product['license']:
                        internal_license = License.objects.create(
                            json=product['license']
                        )

                    # Create Product instance
                    internal_product = Product(
                        scraped_by=scraping_process,
                        sku=product['sku'],
                        title=product['title'],
                        description=product['description'],
                        category=product['category'],
                        source_website=website,
                        license=internal_license,
                    )

                    # If there's a thumbnail, associate it with the product
                    if product['thumbnail_url']:
                        internal_product.thumbnail = ThumbnailImage.objects.create(url=product['thumbnail_url'])

                    # Process the preview file (Page Screenshot)
                    if product['pdf_file_url']:
                        internal_page_screenshot = PageScreenshot.objects.create(url=product['pdf_file_url'])
                        internal_product.page_screenshot = internal_page_screenshot

                    # Save the product
                    internal_product.save()

                    # Now handle the gallery images
                    for gallery_image_url in product['images']:
                        Image.objects.create(
                            product=internal_product,
                            image_url=gallery_image_url
                        )

                    print(f"Product {internal_product.title} saved successfully.")

                except Exception as e:
                    # Handle any errors that occur during the product processing
                    print(f"Error processing product {product.get('sku')}: {e}")
                    continue


        if website.script_name == "stlflix.py":
            stlflix_scraper = StlflixProductScrap(
                scraping_process.search_query,
                scraping_process.max_records
            )
            stlflix_scraper.get_products()
            stlflix_products = stlflix_scraper.to_model_data()
            
            for product in stlflix_products:
                try:
                    # Check if the product already exists
                    existing_product = Product.objects.filter(sku=product['sku']).first()
                    if existing_product:
                        print(f"Product with SKU {product['sku']} already exists. Skipping.")
                        continue
                    
                    # Create Product instance
                    internal_product = Product(
                        scraped_by=scraping_process,
                        sku=product.get('sku'),
                        title=product.get('title'),
                        description=product.get('description') or "No description available",
                        category=product.get('category'),
                        is_commercial_allowed=product.get('is_commercial_allowed'),
                        source_website=website
                    )

                    # If there's a thumbnail, associate it with the product
                    if product.get('thumbnail_url'):
                        internal_product.thumbnail = ThumbnailImage.objects.create(url=product.get('thumbnail_url'))

                    # Save the product
                    internal_product.save()

                    # Now handle the gallery images
                    for gallery_image_url in product.get('images'):
                        Image.objects.create(
                            product=internal_product,
                            image_url=gallery_image_url
                        )

                except Exception as e:
                    # Handle any errors that occur during the product processing
                    print(f"Error processing product {product.get('sku')}: {e}")
                    continue


        if website.script_name == "makerworld.py":
            makerworld_scraper = MakerWorldProductScrap(
                scraping_process.search_query,
                scraping_process.max_records
            )
            makerworld_scraper.get_products()
            makerworld_products = makerworld_scraper.to_model_data()
            
            for product in makerworld_products:
                try:
                    # Check if the product already exists
                    existing_product = Product.objects.filter(sku=product['sku']).first()
                    if existing_product:
                        print(f"Product with SKU {product['sku']} already exists. Skipping.")
                        continue

                    # Create Product instance
                    internal_product = Product(
                        scraped_by=scraping_process,
                        sku=product.get('sku'),
                        title=product.get('title'),
                        description=product.get('description') or "No description available",
                        category=product.get('category'),
                        is_commercial_allowed=product.get('is_commercial_allowed'),
                        source_website=website
                    )

                    # If there's a thumbnail, associate it with the product
                    if product.get('thumbnail_url'):
                        internal_product.thumbnail = ThumbnailImage.objects.create(url=product.get('thumbnail_url'))

                    # Save the product
                    internal_product.save()

                    # Now handle the gallery images
                    for gallery_image_url in product.get('images'):
                        Image.objects.create(
                            product=internal_product,
                            image_url=gallery_image_url
                        )

                except Exception as e:
                    # Handle any errors that occur during the product processing
                    print(f"Error processing product {product.get('sku')}: {e}")
                    continue


@login_required
def initiate_process(request):
    if request.method == 'POST':
        form = ScrapingProcessForm(request.POST)
        if form.is_valid():
            scraping_process = form.save(commit=False)
            scraping_process.started_by = request.user  # Set the current user as 'started_by'
            scraping_process.status = 'pending'  # Set initial status
            scraping_process.save()
            form.save_m2m()  

            # Fetching products
            try:
                processor = ProductScraperProcessor(scraping_process)
                processor.run()
                scraping_process.status = "completed"
                scraping_process.save()
                messages.success(request, "Scraping process has been initiated successfully.")
            except Exception as e:
                scraping_process.status = "failed"
                scraping_process.save()
                messages.error(request, str(e))
                raise Exception(e)

            return redirect('scraper:products')  # Redirect to a page, for example, a list of scraping processes
    else:
        form = ScrapingProcessForm()

    context = {
        'form': form,
        'page': 'initiate-process'

    }
    return render(request, "volt/initiate_process.html", context)


def initiate_scraping_process(request):
    if request.method == 'GET':  # Expecting query parameters in GET request
        form = ScrapingProcessForm(request.GET)
        
        # Validate the form data
        if not form.is_valid():
            errors = form.errors.as_json()
            return JsonResponse({"status": "error", "message": "Invalid form data", "errors": json.loads(errors)}, status=400)
        
        scraping_process = form.save(commit=False)
        scraping_process.started_by = request.user  # Set the current user as 'started_by'
        scraping_process.status = 'pending'  # Set initial status
        scraping_process.save()
        form.save_m2m()  # Save many-to-many relationships like source_websites

        def stream():
            # Yield the initial message
            yield f"data: {json.dumps({'status': 'starting', 'progress': 0, 'total': 0, 'in_percent': 0, 'message': 'Initializing scraping process'})}\n\n"

            try:
                processor = ProductScraperProcessor(scraping_process)
                for update in processor.run_with_streaming():
                    yield f"data: {json.dumps(update)}\n\n"
                scraping_process.status = "completed"
                scraping_process.completed_at = timezone.now() 
                scraping_process.save()
                messages.success(request, "Scraping process has been completed successfully.")

            except Exception as e:
                scraping_process.status = "failed"
                scraping_process.save()
                yield f"data: {json.dumps({'status': 'error', 'progress': 0, 'total': 0, 'in_percent': 0, 'message': str(e)})}\n\n"

        response = StreamingHttpResponse(stream(), content_type="text/event-stream")
        response["Cache-Control"] = "no-cache"
        response["X-Accel-Buffering"] = "no"  # Allow Stream over NGINX server
        return response

    # Return error for invalid method
    return JsonResponse({"status": "error", "message": "Invalid request method"}, status=405)



@login_required
def product_detail(request, product_id):
    # Fetch the product by ID
    product = get_object_or_404(Product, id=product_id)

    # wc_manager = WooCommerceManager()
    # product = wc_manager.upload_product(product.ai_version)
    


    # ai_details = product.generate_ai_details()
    context = {
        'product': product,
        'page': 'products'
    }
    # Render the product detail page
    return render(request, 'volt/product_detail.html', context)



@login_required
def processes_list(request):
    search_query = request.GET.get('q', '')  # Get search query
    per_page = int(request.GET.get('per_page', 10))  # Get products per page, default to 10

    # Filter processes based on the search query
    processes = ScrapingProcess.objects.filter(
        Q(search_query__icontains=search_query) |
        Q(status__icontains=search_query)
    ).distinct().order_by('-id')

    # Paginate the filtered processes
    paginator = Paginator(processes, per_page)
    page_number = request.GET.get('page')
    page_obj = paginator.get_page(page_number)

    context = {
        'page': 'processes',
        'processes': page_obj,
        'search_query': search_query,
        'per_page': per_page,
    }
    return render(request, "volt/process_monitoring.html", context)


def process_products_sse(request):
    verbs = {
      'publish': {
        'doing': 'Publishing',
        'done': 'Published'
      },
      'approve': {
        'doing': 'Approving',
        'done': 'Approved'
      },
      'decline': {
        'doing': 'Declining',
        'done': 'Declined'
      },
      'delete': {
        'doing': 'Deleting',
        'done': 'Deleted'
      }
    }
    operation = request.GET.get('operation')
    product_ids = request.GET.get('ids').split(',')
    total_products = len(product_ids)
    
    operationed = verbs[operation]['done']
    operationing = verbs[operation]['doing']

    def event_stream():
        for idx, product_id in enumerate(product_ids):
            done = idx
            total = total_products
            output = {
                'product_id': product_id,
                'done': done,
                'total': total
            }
            try:
                product = Product.objects.get(id = product_id)
                output['status'] = 'progress'
                output['percent'] = int((done) / total * 100)
                output['message'] = f'{operationing.capitalize()} product ' + product_id
                # Simulate operation (replace with actual logic like WooCommerce upload or AI generation)
                yield f"data: {json.dumps(output)}\n\n"

                # Perform operation
                if operation == 'delete':
                    product.delete()
                    time.sleep(1)
                
                if operation == 'approve' and product.status != 'approved':
                    product.status = 'approved'
                    product.save()

                if operation == 'publish' and product.status != 'published':
                    wc_manager = WooCommerceManager()
                    try:
                        wc_manager.upload_product(product_ai_version=product.ai_version)
                        product.status = 'published'
                        product.save()
                    except Exception as e:
                        # Retry once more
                        output['message'] = "Having problems, retrying without images"
                        yield f"data: {json.dumps(output)}\n\n"

                        try:
                            wc_manager.upload_product(
                                product_ai_version=product.ai_version,
                                exclude_images=True
                            )
                            product.publishing_message = "Published without images"
                            product.status = 'published'
                            product.save()
                        except Exception as second_e:
                            raise Exception(f"Failed to publish product {product_id} after two attempts: {second_e}")


                if operation == 'decline' and product.status != 'declined':
                    product.status = 'declined'
                    product.save()

                # Progress percentage
                done = idx + 1
                progress = int((done) / total * 100)
                output['status'] = 'progress'
                output['percent'] = progress
                output['message'] = f'{progress}% - {operationed.capitalize()} {done} of {total}'

                yield f"data: {json.dumps(output)}\n\n"

            except Exception as e:
                progress = int((done) / total * 100)
                output['status'] = 'error'
                output['percent'] = progress
                output['message'] = f'Error {operationing.capitalize()} product {product_id}: {str(e)}'
                yield f"data: {json.dumps(output)}\n\n"
                # return  # Stop processing on error

        yield f"data: {json.dumps({'status': 'completed', 'message': f'Products {operationed} successfully'})}\n\n"

    response = StreamingHttpResponse(event_stream(), content_type="text/event-stream")
    response["Cache-Control"] = "no-cache"
    response["X-Accel-Buffering"] = "no"  # Allow Stream over NGINX server
    return response

@csrf_exempt
def process_products_operation(request):
    if request.method == 'POST':
        operation = request.POST.get('operation')
        product_ids = request.POST.getlist('product_ids[]')

        if not product_ids:
            return JsonResponse({'success': False, 'message': 'No products selected'})

        try:
            products = Product.objects.filter(id__in=product_ids)
            raise Exception("Invalid product ids")

            if operation == 'publish':
                products.update(status='published')
            elif operation == 'approve':
                products.update(status='approved')
            elif operation == 'decline':
                products.update(status='declined')
            elif operation == 'delete':
                products.delete()
            else:
                return JsonResponse({'success': False, 'message': 'Invalid operation'})

            return JsonResponse({'success': True, 'message': f'{operation} operation completed successfully'})
        except Exception as e:
            return JsonResponse({'success': False, 'message': str(e)})
    return JsonResponse({'success': False, 'message': 'Invalid request method'}, status=405)


@csrf_exempt
def ajax_upload_product_to_wc(request):
    if request.method == 'POST':
        product_ids = request.POST.getlist('product_ids[]', [])

        if not product_ids:
            return JsonResponse({"success": False, "message": "No product IDs provided."}, status=400)

        wc_manager = WooCommerceManager()
        response = None
        if len(product_ids) > 1:
            selected_products = Product.objects.filter(id__in = product_ids)
            products_ai_version = list(map(lambda product: product.ai_version, selected_products))
            try:
                response = wc_manager.upload_bulk_products(products_ai_version)
            except Exception as e:
                return JsonResponse({"success": False, "message": str(e)}, status=500)

        else:
            selected_product = Product.objects.filter(id__in = product_ids).first()
            product_ai_version = selected_product.ai_version
            try:
                response = wc_manager.upload_product(product_ai_version)
            except Exception as e:
                return JsonResponse({"success": False, "message": str(e)}, status=500)

 
        return JsonResponse({"success": True, "message": "All selected products uploaded successfully!", "data": response})
    else:
        return JsonResponse({"success": False, "message": "Invalid request method."}, status=405)



================================================
File: /apps/accounts/urls.py
================================================
from django.urls import path
from . import views
from django.views.i18n import set_language
from django.contrib.auth.decorators import login_required

app_name = "accounts"

urlpatterns = [
    path('', views.home_view, name='home'),
   
    path('accounts/profile/', views.my_profile, name='profile'),
    path(
        'accounts/profile/change-password', 
        login_required(views.CustomCurrentUserPasswordChangeView.as_view()),
        name='change-profile-password'
    ),
    path('accounts/profile/edit', views.edit_profile, name='edit-profile'),
    path('accounts/login/', views.login_view, name='login'),
    path('accounts/logout/', views.logout_view, name='logout'),



]


================================================
File: /apps/accounts/views.py
================================================


@login_required
def my_profile(request):
    user = request.user
    fields_data = {}
    exclude = ['password', 'is_active', 'is_deleted', 'is_superuser', 'is_admin', 'is_staff', 'profile_picture', 'is_staff']
    for field in user._meta.fields:
        if field.name not in exclude:
            key = field.verbose_name
            value = getattr(user, field.name)
            fields_data[key] = value

    context = {
        'fields_data': fields_data
    }
    return render(request, "myprofile.html", context)







# Django view
@login_required
def settings_view(request):
    config_form = ConfigForm()
    wc_config_form = WoocommerceConfigForm()

    if request.method == "POST":
        form_type = request.POST.get('form_type')
        if form_type == 'openai_config':
            config_form = ConfigForm(request.POST)
            if config_form.is_valid():
                config_form.save()
                messages.success(request, "OpenAI configuration updated successfully.")
                return redirect('accounts:settings')
        else:
            wc_config_form = WoocommerceConfigForm(request.POST)
            if wc_config_form.is_valid():
                wc_config_form.save()
                messages.success(request, "WooCommerce configuration updated successfully.")
                return redirect('accounts:settings')

    context = {
        'config_form': config_form,
        'wc_config_form': wc_config_form,
        'page': 'settings'
    }
    return render(request, "volt/settings.html", context)



@login_required
def home_view(request):
    total_days = 10

    # Calculate date range
    start_date = (timezone.now() - timedelta(days=total_days)).date()
    end_date = timezone.now().date()  # Explicitly get today's date

    # Aggregate product counts
    stats = Product.objects.aggregate(
        total=Count('id'),
        published=Count('id', filter=Q(status='published')),
        declined=Count('id', filter=Q(status='declined')),
    )

    # Get daily counts for products
    daily_counts = (
        Product.objects.filter(created_at__date__gte=start_date)
        .annotate(date=TruncDate('created_at'))
        .values('date')
        .annotate(count=Count('id'))
        .order_by('date')
    )

    labels = [(start_date + timedelta(days=i+1)).strftime('%Y-%m-%d') for i in range(total_days)]
    print(labels)
    data = [0] * total_days

    for entry in daily_counts:
        entry_date = entry['date'].strftime('%Y-%m-%d')
        if entry_date in labels:
            date_index = labels.index(entry_date)
            data[date_index] = entry['count']

    product_graph_data = {
        'labels': labels,
        'data': data,
    }

    # Get OpenAI API usage data
    openai_daily_usage = (
        OpenAIAPIUsage.objects.filter(request_timestamp__date__gte=start_date)
        .annotate(date=TruncDate('request_timestamp'))
        .values('date')
        .annotate(
            total_tokens=Sum('total_tokens'),
            prompt_tokens=Sum('prompt_tokens'),
            completion_tokens=Sum('completion_tokens'),
            response_count=Count('*')  # Count the total number of requests (objects)
        )
        .order_by('date')
    )

    openai_data = {label: {'total': 0, 'prompt': 0, 'completion': 0, 'response_count': 0} for label in labels}

    for usage in openai_daily_usage:
        entry_date = usage['date'].strftime('%Y-%m-%d')
        if entry_date in openai_data:
            openai_data[entry_date] = {
                'total': usage['total_tokens'],
                'prompt': usage['prompt_tokens'],
                'completion': usage['completion_tokens'],
                'response_count': usage['response_count'],
            }

    # Populate OpenAI graph data
    openai_graph_data = {
        'labels': labels,
        'total_tokens': [openai_data[date]['total'] for date in labels],
        'prompt_tokens': [openai_data[date]['prompt'] for date in labels],
        'completion_tokens': [openai_data[date]['completion'] for date in labels],
        'response_count': [openai_data[date]['response_count'] for date in labels],
    }

    # code to caclulate success ratio of scraping process
    success_ratio = 0
    total_scraping_process = ScrapingProcess.objects.all().count()
    if total_scraping_process > 0:
        completed_scraping_process = ScrapingProcess.objects.filter(status='completed').count()
        success_ratio = completed_scraping_process / total_scraping_process * 100
        success_ratio = f'{round(success_ratio, 0)}% ({completed_scraping_process})'

    context = {
        'total_openai_requests': OpenAIAPIUsage.objects.all().count(),
        'all_scraping_process': total_scraping_process,
        'scraping_success_ratio': success_ratio,
        'page': 'dashboard',
        'total_products': stats['total'],
        'published_products': stats['published'],
        'declined_products': stats['declined'],
        'graph_data': product_graph_data,
        'openai_graph_data': openai_graph_data,
    }
    return render(request, "volt/dashboard.html", context)




def login_view(request):
    if request.user.is_authenticated:
        return redirect("accounts:home")
    
    
    if request.method == 'POST':
        form = AuthenticationForm(request, data=request.POST)
        if form.is_valid():
            user = form.get_user()
            login(request, user)
            next_path = request.POST.get("next")
            
            messages.success(request, "You've been logged successfully.")
            if next_path:
                return redirect(next_path)
            

            return redirect('accounts:home')
    else:
        form = AuthenticationForm()
    return render(request, 'volt/signin.html', {'form': form})


@login_required
def logout_view(request):
    logout(request)
    return redirect('accounts:login')


